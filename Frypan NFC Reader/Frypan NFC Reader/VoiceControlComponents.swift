//
//  VoiceControlComponents.swift
//  Frypan NFC Reader
//
//  Created by Claude on 5/9/2025.
//

import SwiftUI
import AVFoundation

// MARK: - Talk Button View
struct TalkButtonView: View {
    @ObservedObject var voiceManager: VoiceControlManager
    @ObservedObject var speechRecognizer: SpeechRecognizer
    @State private var pulseScale: CGFloat = 1.0
    @State private var pulseOpacity: Double = 0.6
    let onStartRecording: () -> Void
    let onStopRecording: () -> Void
    let onCancelRecording: () -> Void
    let onConfirmRecording: () -> Void
    
    var body: some View {
        Button(action: {
            // Empty action, using gestures instead
        }) {
            ZStack {
                // å¤–åœˆè„ˆè¡å‹•ç•« - æŒçºŒé¡¯ç¤ºä»¥å¸å¼•ç”¨æˆ¶
                Circle()
                    .stroke(Color.blue.opacity(0.6), lineWidth: 3)
                    .scaleEffect(pulseScale)
                    .opacity(pulseOpacity)
                    .frame(width: 110, height: 110)
                    .animation(
                        .easeInOut(duration: 1.1).repeatForever(autoreverses: true),
                        value: pulseScale
                    )
                
                // ä¸»æŒ‰éˆ•
                Circle()
                    .fill(voiceManager.isPressingTalkButton ? 
                          (voiceManager.slideOffset < -50 ? Color.red : 
                            voiceManager.slideOffset > 50 ? Color.green : Color.gray) : Color.blue.opacity(0.6))
                    .frame(width: 90, height: 90)
                    .animation(.easeInOut(duration: 0.1), value: voiceManager.slideOffset)
                    .animation(.easeInOut(duration: 0.1), value: voiceManager.isPressingTalkButton)
                
                // éº¥å…‹é¢¨åœ–æ¨™
                Image(systemName: speechRecognizer.isRecognizing ? "microphone.badge.ellipsis.fill" : "microphone.fill")
                    .font(.system(size: 50, weight: .regular))
                    .foregroundColor(.white)
            }
        }
        .simultaneousGesture(
            DragGesture(minimumDistance: 0)
                .onChanged { value in
                    handleDragChanged(value)
                }
                .onEnded { value in
                    handleDragEnded(value)
                }
        )
        .onAppear {
            // å•Ÿå‹•è„ˆè¡å‹•ç•«
            startPulseAnimation()
        }
    }
    
    private func startPulseAnimation() {
        // è¨­ç½®è„ˆè¡å‹•ç•«ç›®æ¨™å€¼
        pulseScale = 1.3
        pulseOpacity = 0.2
    }
    
    private func handleDragChanged(_ value: DragGesture.Value) {
        // ç¢ºä¿åˆå§‹åŒ–å®Œæˆ
        guard voiceManager.isInitialized else {
            print("âš ï¸ æŒ‰å£“èªªè©±åŠŸèƒ½å°šæœªåˆå§‹åŒ–å®Œæˆ")
            return
        }
        
        voiceManager.isPressingTalkButton = true
        
        if !speechRecognizer.isRecognizing {
            print("ğŸ¤ é–‹å§‹èªéŸ³è­˜åˆ¥")
            // æ¸…ç©ºä¹‹å‰çš„è­˜åˆ¥æ–‡æœ¬
            speechRecognizer.recognizedText = ""
            onStartRecording()
            DispatchQueue.main.async {
                withAnimation(.easeInOut(duration: 0.3)) {
                    voiceManager.showSlideControls = true
                }
            }
        } else if !voiceManager.showSlideControls {
            // å¦‚æœå·²ç¶“åœ¨éŒ„éŸ³ä½†æ§ä»¶æ²’é¡¯ç¤ºï¼Œç¢ºä¿é¡¯ç¤º
            DispatchQueue.main.async {
                withAnimation(.easeInOut(duration: 0.3)) {
                    voiceManager.showSlideControls = true
                }
            }
        }
        
        // è¨ˆç®—æ»‘å‹•åç§»ï¼Œé™åˆ¶æœ€å¤§æ»‘å‹•è·é›¢
        voiceManager.slideOffset = max(-100, min(100, value.translation.width))
        
        // æ›´æ–°ç•¶å‰æ»‘å‹•æ“ä½œç‹€æ…‹ï¼Œä½†ä¸ç«‹å³åŸ·è¡Œ
        if voiceManager.slideOffset < -50 {
            voiceManager.currentSlideAction = .cancel
        } else if voiceManager.slideOffset > 50 {
            voiceManager.currentSlideAction = .confirm
        } else {
            voiceManager.currentSlideAction = VoiceControlManager.SlideAction.none
        }
    }
    
    private func handleDragEnded(_ value: DragGesture.Value) {
        voiceManager.isPressingTalkButton = false
        
        // æ ¹æ“šæ‰‹æŒ‡é›¢é–‹æ™‚çš„ä½ç½®æ±ºå®šæ“ä½œ
        if let action = voiceManager.currentSlideAction {
            switch action {
            case .cancel:
                print("ğŸš« æ‰‹æŒ‡é›¢é–‹å–æ¶ˆå€åŸŸï¼Œå–æ¶ˆéŒ„éŸ³")
                onCancelRecording()
                // å–æ¶ˆæ“ä½œå¾Œé‡ç½®ç‹€æ…‹
                DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) {
                    voiceManager.resetRecordingState(speechRecognizer: speechRecognizer)
                }
            case .confirm:
                print("âœ… æ‰‹æŒ‡é›¢é–‹ç¢ºèªå€åŸŸï¼Œç¢ºèªéŒ„éŸ³")
                onConfirmRecording()
                // ç¢ºèªæ“ä½œå¾Œé‡ç½®ç‹€æ…‹
                DispatchQueue.main.asyncAfter(deadline: .now() + 1.0) {
                    voiceManager.resetRecordingState(speechRecognizer: speechRecognizer)
                }
            case .none:
                print("âš ï¸ æ‰‹æŒ‡é›¢é–‹ä¸­æ€§å€åŸŸï¼Œè¦–ç‚ºå–æ¶ˆ")
                onStopRecording()
                // å»¶é²é‡ç½®æ‰€æœ‰ç‹€æ…‹
                DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) {
                    voiceManager.resetRecordingState(speechRecognizer: speechRecognizer)
                }
            }
        } else {
            print("âš ï¸ æ‰‹æŒ‡é›¢é–‹ï¼ŒcurrentSlideAction ç‚º nilï¼Œè¦–ç‚ºå–æ¶ˆ")
            onStopRecording()
            // å»¶é²é‡ç½®æ‰€æœ‰ç‹€æ…‹
            DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) {
                voiceManager.resetRecordingState(speechRecognizer: speechRecognizer)
            }
        }
        
        // ç«‹å³éš±è—æ»‘å‹•æ§åˆ¶
        withAnimation(.easeInOut(duration: 0.2)) {
            voiceManager.showSlideControls = false
            voiceManager.slideOffset = 0
            voiceManager.currentSlideAction = VoiceControlManager.SlideAction.none
        }
    }
}

// MARK: - Slide Controls View
struct SlideControlsView: View {
    @ObservedObject var voiceManager: VoiceControlManager
    
    var body: some View {
        if voiceManager.showSlideControls {
            HStack(spacing: 110) {
                // å–æ¶ˆæŒ‰éˆ•
                Circle()
                    .fill(voiceManager.slideOffset < -50 ? Color.red.opacity(0.8) : Color.red.opacity(0.3))
                    .frame(width: 80, height: 80)
                    .overlay(
                        Image(systemName: "xmark")
                            .font(.system(size: 33, weight: .bold))
                            .foregroundColor(.white)
                            .scaleEffect(voiceManager.slideOffset < -50 ? 1.2 : 1.0)
                    )
                    .animation(.easeInOut(duration: 0.2), value: voiceManager.slideOffset)
                
                // ç¢ºèªæŒ‰éˆ•
                Circle()
                    .fill(voiceManager.slideOffset > 50 ? Color.green.opacity(0.8) : Color.green.opacity(0.3))
                    .frame(width: 80, height: 80)
                    .overlay(
                        Image(systemName: "checkmark")
                            .font(.system(size: 33, weight: .bold))
                            .foregroundColor(.white)
                            .scaleEffect(voiceManager.slideOffset > 50 ? 1.2 : 1.0)
                    )
                    .animation(.easeInOut(duration: 0.3), value: voiceManager.slideOffset)
            }
            .padding(.horizontal, 20)
            .transition(.asymmetric(
                insertion: .move(edge: .bottom).combined(with: .opacity),
                removal: .move(edge: .bottom).combined(with: .opacity)
            ))
            .animation(.easeInOut(duration: 0.3), value: voiceManager.showSlideControls)
        }
    }
}

// MARK: - Speech Recognition Status View
struct SpeechRecognitionStatusView: View {
    @ObservedObject var speechRecognizer: SpeechRecognizer
    @ObservedObject var voiceManager: VoiceControlManager
    
    var body: some View {
        if !speechRecognizer.recognizedText.isEmpty && speechRecognizer.isRecognizing && voiceManager.isPressingTalkButton {
            VStack(spacing: 4) {
                Text("è­˜åˆ¥ä¸­...")
                    .font(.caption)
                    .foregroundColor(.white.opacity(0.8))
                
                Text(speechRecognizer.recognizedText)
                    .font(.body)
                    .foregroundColor(.white)
                    .multilineTextAlignment(.center)
                    .padding(.horizontal, 20)
                    .padding(.vertical, 8)
                    .background(Color.blue.opacity(0.2))
                    .cornerRadius(8)
            }
            .padding(.bottom, 8)
        }
    }
}
