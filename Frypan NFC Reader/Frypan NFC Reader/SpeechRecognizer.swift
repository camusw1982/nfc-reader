//
//  SpeechRecognizer.swift
//  Frypan NFC Reader
//
//  Created by Claude on 5/9/2025.
//

import Foundation
import Speech
import SwiftUI
import AVFoundation
import Combine

class SpeechRecognizer: NSObject, ObservableObject, SFSpeechRecognizerDelegate {
    @Published var isRecognizing = false
    @Published var recognizedText = ""
    @Published var hasPermission = false
    @Published var error: String?
    @Published var lastSentText: String?
    @Published var llmResponse: String = ""
    @Published var originalText: String = ""
    @Published var responseTimestamp: Date?
    @Published var isWebSocketConnected = false
    @Published var isRecordingCancelled = false
    
    // å°è©±æ¶ˆæ¯æ•¸çµ„
    @Published var messages: [ChatMessage] = []
    
    let webService = WebServiceManager()
    
    private var speechRecognizer: SFSpeechRecognizer?
    private var recognitionRequest: SFSpeechAudioBufferRecognitionRequest?
    private var recognitionTask: SFSpeechRecognitionTask?
    private let audioEngine = AVAudioEngine()
    private let audioSession = AVAudioSession.sharedInstance()
    private var cancellables = Set<AnyCancellable>()
    
    override init() {
        super.init()
        setupSpeechRecognizer()
        requestPermission()
        setupWebSocketMonitoring()
    }
    
    private func setupSpeechRecognizer() {
        // æ™ºèƒ½èªè¨€æª¢æ¸¬ï¼Œå„ªå…ˆæ”¯æŒç²µèªå’Œä¸­æ–‡
        let languageOptions = [
            "zh-HK",  // é¦™æ¸¯ç¹é«”ä¸­æ–‡ï¼ˆç²µèªï¼‰
            "zh-TW",  // å°ç£ç¹é«”ä¸­æ–‡
            "zh-CN",  // ç°¡é«”ä¸­æ–‡
            "en-US",  // ç¾å¼è‹±èª
            "en-GB"   // è‹±å¼è‹±èª
        ]
        
        // å˜—è©¦æŒ‰å„ªå…ˆé †åºåˆå§‹åŒ–èªéŸ³è­˜åˆ¥å™¨
        for language in languageOptions {
            if let recognizer = SFSpeechRecognizer(locale: Locale(identifier: language)) {
                if recognizer.isAvailable {
                    speechRecognizer = recognizer
                    speechRecognizer?.delegate = self
                    print("âœ… æˆåŠŸåˆå§‹åŒ–èªéŸ³è­˜åˆ¥å™¨ï¼Œèªè¨€: \(language)")
                    return
                }
            }
        }
        
        // å¦‚æœæ‰€æœ‰èªè¨€éƒ½ä¸å¯ç”¨ï¼Œä½¿ç”¨ç³»çµ±é»˜èª
        speechRecognizer = SFSpeechRecognizer(locale: Locale.current)
        speechRecognizer?.delegate = self
        print("â„¹ï¸ ä½¿ç”¨ç³»çµ±é»˜èªèªè¨€: \(Locale.current.identifier)")
    }
    
    func requestPermission() {
        SFSpeechRecognizer.requestAuthorization { [weak self] status in
            DispatchQueue.main.async {
                switch status {
                case .authorized:
                    self?.hasPermission = true
                    print("âœ… èªéŸ³è­˜åˆ¥æ¬Šé™å·²æˆäºˆ")
                case .denied:
                    self?.error = "èªéŸ³è­˜åˆ¥æ¬Šé™è¢«æ‹’çµ•"
                case .restricted:
                    self?.error = "èªéŸ³è­˜åˆ¥åŠŸèƒ½å—é™"
                case .notDetermined:
                    self?.error = "èªéŸ³è­˜åˆ¥æ¬Šé™æœªç¢ºå®š"
                @unknown default:
                    self?.error = "æœªçŸ¥çš„æ¬Šé™ç‹€æ…‹"
                }
            }
        }
    }
    
    func startRecording() {
        guard hasPermission else {
            error = "æ²’æœ‰èªéŸ³è­˜åˆ¥æ¬Šé™"
            return
        }
        
        guard let speechRecognizer = speechRecognizer, speechRecognizer.isAvailable else {
            error = "èªéŸ³è­˜åˆ¥æœå‹™ä¸å¯ç”¨"
            return
        }
        
        guard !isRecognizing else {
            print("èªéŸ³è­˜åˆ¥å·²åœ¨é€²è¡Œä¸­")
            return
        }
        
        // å–æ¶ˆä¹‹å‰çš„ä»»å‹™
        if let recognitionTask = recognitionTask {
            recognitionTask.cancel()
            self.recognitionTask = nil
        }
        
        // é…ç½®éŸ³é »æœƒè©±
        do {
            try audioSession.setCategory(.playAndRecord, mode: .default, options: [.defaultToSpeaker])
            try audioSession.setActive(true)
        } catch {
            self.error = "éŸ³é »æœƒè©±é…ç½®å¤±æ•—: \(error.localizedDescription)"
            return
        }
        
        // å‰µå»ºè­˜åˆ¥è«‹æ±‚
        recognitionRequest = SFSpeechAudioBufferRecognitionRequest()
        guard let recognitionRequest = recognitionRequest else {
            error = "ç„¡æ³•å‰µå»ºè­˜åˆ¥è«‹æ±‚"
            return
        }
        
        recognitionRequest.shouldReportPartialResults = true
        
        // ç°¡åŒ–ï¼šåªä½¿ç”¨åœ¨ç·šè­˜åˆ¥ï¼Œé¿å…é›¢ç·šè­˜åˆ¥çš„ 1101 éŒ¯èª¤
        recognitionRequest.requiresOnDeviceRecognition = false
        
        // é–‹å§‹è­˜åˆ¥ä»»å‹™
        recognitionTask = speechRecognizer.recognitionTask(with: recognitionRequest) { [weak self] result, error in
            guard let self = self else { return }
            
            if let result = result {
                let transcribedString = result.bestTranscription.formattedString
                DispatchQueue.main.async {
                    self.recognizedText = transcribedString
                    if result.isFinal {
                        print("ğŸ¤ èªéŸ³è­˜åˆ¥å®Œæˆ: \(transcribedString)")
                    }
                }
            }
            
            if let error = error {
                let errorDescription = error.localizedDescription
                
                // éæ¿¾æ‰æ­£å¸¸æƒ…æ³çš„éŒ¯èª¤
                if errorDescription == "No speech detected" || 
                   errorDescription == "Recognition request was canceled" ||
                   errorDescription.contains("kAFAssistantErrorDomain error 216") {
                    print("â„¹ï¸ \(errorDescription) (æ­£å¸¸æƒ…æ³)")
                } else {
                    DispatchQueue.main.async {
                        self.error = "è­˜åˆ¥éŒ¯èª¤: \(errorDescription)"
                        print("âŒ èªéŸ³è­˜åˆ¥éŒ¯èª¤: \(errorDescription)")
                    }
                }
            }
        }
        
        // é…ç½®éŸ³é »è¼¸å…¥
        let inputNode = audioEngine.inputNode
        let recordingFormat = inputNode.outputFormat(forBus: 0)
        
        inputNode.installTap(onBus: 0, bufferSize: 1024, format: recordingFormat) { [weak self] buffer, _ in
            self?.recognitionRequest?.append(buffer)
        }
        
        // å•Ÿå‹•éŸ³é »å¼•æ“
        do {
            audioEngine.prepare()
            try audioEngine.start()
            DispatchQueue.main.async {
                self.isRecognizing = true
                self.error = nil
                print("ğŸ¤ èªéŸ³è­˜åˆ¥å·²é–‹å§‹")
            }
        } catch {
            self.error = "éŸ³é »å¼•æ“å•Ÿå‹•å¤±æ•—: \(error.localizedDescription)"
            stopRecording()
        }
    }
    
    func stopRecording() {
        stopRecording(shouldSendResult: false)
    }
    
    func stopRecording(shouldSendResult: Bool) {
        if isRecognizing {
            // åœæ­¢éŸ³é »å¼•æ“
            if audioEngine.isRunning {
                audioEngine.stop()
            }
            
            // ç§»é™¤éŸ³é »è¼¸å…¥ç¯€é»
            if audioEngine.inputNode.numberOfInputs > 0 {
                audioEngine.inputNode.removeTap(onBus: 0)
            }
            
            // çµæŸéŸ³é »è«‹æ±‚
            recognitionRequest?.endAudio()
            recognitionRequest = nil
            
            // å–æ¶ˆè­˜åˆ¥ä»»å‹™
            recognitionTask?.cancel()
            recognitionTask = nil
            
            // åœç”¨éŸ³é »æœƒè©±
            do {
                try audioSession.setActive(false, options: .notifyOthersOnDeactivation)
            } catch {
                print("âš ï¸ åœç”¨éŸ³é »æœƒè©±å¤±æ•—: \(error.localizedDescription)")
            }
            
            DispatchQueue.main.async {
                self.isRecognizing = false
                print("ğŸ›‘ èªéŸ³è­˜åˆ¥å·²åœæ­¢")
                
                // å¦‚æœæœ‰è­˜åˆ¥çµæœä¸”éœ€è¦ç™¼é€ï¼Œä¸”éŒ„éŸ³æœªè¢«å–æ¶ˆï¼Œç™¼é€åˆ°æœå‹™å™¨
                if shouldSendResult && !self.recognizedText.isEmpty && !self.isRecordingCancelled {
                    self.sendToServer()
                }
                
                // é‡ç½®å–æ¶ˆæ¨™èªŒ
                self.isRecordingCancelled = false
            }
        }
    }
    
    private func sendToServer() {
        // é€™å€‹æ–¹æ³•ä¿ç•™ç”¨æ–¼å‘å¾Œå…¼å®¹ï¼Œä½†å¯¦éš›ç™¼é€é‚è¼¯æ‡‰è©²åœ¨èª¿ç”¨æ–¹è™•ç†
        print("ğŸ“¤ èªéŸ³è­˜åˆ¥çµæœ: \(recognizedText)")
    }
    
    func reset() {
        stopRecording()
        DispatchQueue.main.async {
            self.recognizedText = ""
            self.error = nil
            self.llmResponse = ""
            self.originalText = ""
            self.responseTimestamp = nil
            self.isRecordingCancelled = false
            self.messages.removeAll()
        }
    }
    
    func clearChat() {
        DispatchQueue.main.async {
            self.messages.removeAll()
        }
    }
    
    // MARK: - èªè¨€æ”¯æŒæª¢æŸ¥
    func getCurrentLanguage() -> String {
        guard let recognizer = speechRecognizer else {
            return "æœªçŸ¥"
        }
        return recognizer.locale.identifier
    }
    
    func checkLanguageSupport() -> String {
        let supportedLanguages = [
            "zh-HK": "é¦™æ¸¯ç¹é«”ä¸­æ–‡ï¼ˆç²µèªï¼‰",
            "zh-TW": "å°ç£ç¹é«”ä¸­æ–‡",
            "zh-CN": "ç°¡é«”ä¸­æ–‡",
            "en-US": "ç¾å¼è‹±èª",
            "en-GB": "è‹±å¼è‹±èª"
        ]
        
        var availableLanguages: [String] = []
        
        for (code, name) in supportedLanguages {
            if let recognizer = SFSpeechRecognizer(locale: Locale(identifier: code)) {
                if recognizer.isAvailable {
                    availableLanguages.append(name)
                }
            }
        }
        
        if availableLanguages.isEmpty {
            return "âŒ æ²’æœ‰å¯ç”¨çš„èªéŸ³è­˜åˆ¥èªè¨€"
        } else {
            let currentLang = getCurrentLanguage()
            let currentLangName = supportedLanguages[currentLang] ?? currentLang
            return """
            âœ… ç•¶å‰èªè¨€: \(currentLangName)
            
            å¯ç”¨èªè¨€:
            â€¢ \(availableLanguages.joined(separator: "\nâ€¢ "))
            """
        }
    }
    
    // MARK: - è¨­å‚™è¨­ç½®æª¢æŸ¥
    func checkDeviceSettings() -> String {
        var issues: [String] = []
        var recommendations: [String] = []
        
        // æª¢æŸ¥èªéŸ³è­˜åˆ¥æ¬Šé™
        let authStatus = SFSpeechRecognizer.authorizationStatus()
        switch authStatus {
        case .denied:
            issues.append("èªéŸ³è­˜åˆ¥æ¬Šé™è¢«æ‹’çµ•")
            recommendations.append("å‰å¾€ è¨­ç½® > éš±ç§èˆ‡å®‰å…¨æ€§ > èªéŸ³è­˜åˆ¥ å•Ÿç”¨æ¬Šé™")
        case .restricted:
            issues.append("èªéŸ³è­˜åˆ¥åŠŸèƒ½å—é™")
            recommendations.append("æª¢æŸ¥è¨­å‚™é™åˆ¶è¨­ç½®")
        case .notDetermined:
            issues.append("èªéŸ³è­˜åˆ¥æ¬Šé™æœªç¢ºå®š")
            recommendations.append("æ‡‰ç”¨ç¨‹åºéœ€è¦èªéŸ³è­˜åˆ¥æ¬Šé™")
        case .authorized:
            break
        @unknown default:
            issues.append("æœªçŸ¥çš„æ¬Šé™ç‹€æ…‹")
        }
        
        // æª¢æŸ¥èªéŸ³è­˜åˆ¥å™¨å¯ç”¨æ€§
        if let recognizer = speechRecognizer {
            if !recognizer.isAvailable {
                issues.append("èªéŸ³è­˜åˆ¥æœå‹™ä¸å¯ç”¨")
                recommendations.append("æª¢æŸ¥ç¶²çµ¡é€£æ¥æˆ–é‡å•Ÿè¨­å‚™")
            }
        } else {
            issues.append("ç„¡æ³•åˆå§‹åŒ–èªéŸ³è­˜åˆ¥å™¨")
            recommendations.append("é‡å•Ÿæ‡‰ç”¨ç¨‹åºæˆ–æª¢æŸ¥è¨­å‚™è¨­ç½®")
        }
        
        // æ·»åŠ èªè¨€æ”¯æŒæª¢æŸ¥
        let languageInfo = checkLanguageSupport()
        
        if issues.isEmpty {
            return """
            âœ… è¨­å‚™è¨­ç½®æ­£å¸¸ï¼ŒèªéŸ³è­˜åˆ¥åŠŸèƒ½å¯ç”¨
            
            \(languageInfo)
            """
        } else {
            let issueText = issues.joined(separator: "ã€")
            let recommendationText = recommendations.joined(separator: "\nâ€¢ ")
            
            return """
            âš ï¸ è¨­å‚™è¨­ç½®å•é¡Œï¼š\(issueText)
            
            å»ºè­°è§£æ±ºæ–¹æ¡ˆï¼š
            â€¢ \(recommendationText)
            â€¢ ç¢ºä¿è¨­å‚™å·²é€£æ¥ç¶²çµ¡ï¼ˆä½¿ç”¨åœ¨ç·šèªéŸ³è­˜åˆ¥ï¼‰
            â€¢ æª¢æŸ¥è¨­å‚™èªè¨€è¨­ç½®æ˜¯å¦æ”¯æŒç²µèª
            
            \(languageInfo)
            """
        }
    }
    
    private func setupWebSocketMonitoring() {
        // ç›£è½ WebSocket é€£æ¥ç‹€æ…‹
        if let webSocketManager = webService.getWebSocketManager() {
            webSocketManager.$isConnected.sink { [weak self] isConnected in
                DispatchQueue.main.async {
                    self?.isWebSocketConnected = isConnected
                    print("ğŸ”Œ WebSocket é€£æ¥ç‹€æ…‹: \(isConnected)")
                }
            }.store(in: &cancellables)
            
            // ç›£è½æ”¶åˆ°çš„æ¶ˆæ¯
            webSocketManager.$receivedMessages.sink { [weak self] messages in
                guard let self = self, let lastMessage = messages.last else { return }
                
                // è§£æ Gemini å›æ‡‰
                if let data = lastMessage.data(using: .utf8),
                   let json = try? JSONSerialization.jsonObject(with: data, options: []) as? [String: Any] {
                    
                    if let type = json["type"] as? String {
                        if type == "response" || type == "gemini_response" {
                            if let response = json["response"] as? String {
                                DispatchQueue.main.async {
                                    self.llmResponse = response
                                    self.responseTimestamp = Date()
                                    print("ğŸ¤– æ”¶åˆ° Gemini å›æ‡‰: \(response)")
                                    
                                    // æ·»åŠ  AI å›æ‡‰åˆ°å°è©±
                                    let aiMessage = ChatMessage(text: response, isUser: false, timestamp: Date(), isError: false)
                                    self.messages.append(aiMessage)
                                }
                            }
                            if let originalText = json["original_text"] as? String {
                                DispatchQueue.main.async {
                                    self.originalText = originalText
                                    print("ğŸ“ åŸå§‹æ–‡æœ¬: \(originalText)")
                                }
                            }
                        } else if type == "pong" {
                            print("ğŸ“ æœå‹™å™¨éŸ¿æ‡‰æ­£å¸¸")
                        } else if type == "history", let history = json["history"] as? [[String: Any]] {
                            print("ğŸ“š æ”¶åˆ°æ­·å²è¨˜éŒ„: \(history.count) æ¢å°è©±")
                        }
                    }
                } else {
                    // å¦‚æœä¸æ˜¯ JSON æ ¼å¼ï¼Œç›´æ¥ä½œç‚ºå›æ‡‰è™•ç†
                    DispatchQueue.main.async {
                        self.llmResponse = lastMessage
                        print("ğŸ¤– æ”¶åˆ°æ–‡æœ¬å›æ‡‰: \(lastMessage)")
                        
                        // æ·»åŠ  AI å›æ‡‰åˆ°å°è©±
                        let aiMessage = ChatMessage(text: lastMessage, isUser: false, timestamp: Date(), isError: false)
                        self.messages.append(aiMessage)
                    }
                }
            }.store(in: &cancellables)
        }
    }
    
    // MARK: - SFSpeechRecognizerDelegate
    
    func speechRecognizer(_ speechRecognizer: SFSpeechRecognizer, availabilityDidChange available: Bool) {
        DispatchQueue.main.async {
            if available {
                print("âœ… èªéŸ³è­˜åˆ¥å¯ç”¨")
            } else {
                print("âŒ èªéŸ³è­˜åˆ¥ä¸å¯ç”¨")
                self.error = "èªéŸ³è­˜åˆ¥æš«æ™‚ä¸å¯ç”¨"
            }
        }
    }
}